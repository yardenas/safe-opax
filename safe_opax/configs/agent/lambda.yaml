defaults:
  - penalizer/lagrangian

name: lambda
replay_buffer:
  batch_size: 32
  sequence_length: 64
  num_shots: 4
  capacity: 1000
model:
  num_context_layers: 2
  hidden_size: 128
  intermediate_size: 512
  num_heads: 2
  context_size: 64
  stochastic_size: 64
  deterministic_size: 128
actor:
  n_layers: 4
  hidden_size: 400
  init_stddev: 5.
critic:
  n_layers: 3
  hidden_size: 400
actor_optimizer:
  lr: 8e-5
  eps: 1e-5
  clip: 0.5
critic_optimizer:
  lr: 8e-5
  eps: 1e-5
  clip: 0.5
safety_critic_optimizer:
  lr: 8e-5
  eps: 1e-5
  clip: 0.5
model_optimizer:
  lr: 3e-4
  eps: 1e-5
  clip: 0.5
discount: 0.99
safety_discount: 0.99
lambda_: 0.97
plan_horizon: 15
update_steps: 20
train_every: 4
beta_context: 0.1
beta_model: 0.0001
free_nats_context: 2.
free_nats_model: 1.5
safety_slack: 1.